{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "canadian-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "df = pd.read_csv(\"mnist.csv\")\n",
    "X = df.drop(columns=[\"class\"]).to_numpy()\n",
    "Y = df[\"class\"].to_numpy()\n",
    "\n",
    "# no hay que normalizar\n",
    "# no hay que codificar\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC()\n",
    "params = {\n",
    "    \"C\": (1, 2, 10),\n",
    "    \"max_iter\": (100,)\n",
    "}\n",
    "svm_linear_cv = GridSearchCV(svc, params, cv=3)\n",
    "svm_linear_cv.fit(X_train, Y_train)\n",
    "svm_linear_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "final_svc = LinearSVC(C=1, max_iter=1000)\n",
    "final_svc.fit(X, Y)\n",
    "dump(final_svc, \"svm_linear.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mobile-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer([28, 28, 1]),\n",
    "    # Preprocessing\n",
    "    preprocessing.RandomRotation(factor=0.2),\n",
    "    preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    preprocessing.RandomZoom(height_factor=0.5, width_factor=0.5),\n",
    "    # Base\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"SAME\"),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    # Head\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adee8aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc52ff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_rotation_2 (RandomRot (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "random_translation_2 (Random (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "random_zoom_2 (RandomZoom)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              12846080  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 13,382,794\n",
      "Trainable params: 13,379,722\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f22bd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f37b10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_images = np.array([image.reshape(28, 28, 1) for image in X_train])\n",
    "X_test_images = np.array([image.reshape(28, 28, 1) for image in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "027b37e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1662/1662 [==============================] - 176s 105ms/step - loss: 1.4808 - accuracy: 0.5131 - val_loss: 1.0107 - val_accuracy: 0.7468\n",
      "Epoch 2/10\n",
      "1662/1662 [==============================] - 185s 112ms/step - loss: 0.9406 - accuracy: 0.6890 - val_loss: 0.5772 - val_accuracy: 0.8537\n",
      "Epoch 3/10\n",
      "1662/1662 [==============================] - 174s 105ms/step - loss: 0.8136 - accuracy: 0.7373 - val_loss: 0.5669 - val_accuracy: 0.8621\n",
      "Epoch 4/10\n",
      "1662/1662 [==============================] - 186s 112ms/step - loss: 0.7408 - accuracy: 0.7599 - val_loss: 0.8197 - val_accuracy: 0.8206\n",
      "Epoch 5/10\n",
      "1662/1662 [==============================] - 190s 114ms/step - loss: 0.6960 - accuracy: 0.7741 - val_loss: 0.3842 - val_accuracy: 0.9014\n",
      "Epoch 6/10\n",
      "1662/1662 [==============================] - 185s 112ms/step - loss: 0.6592 - accuracy: 0.7895 - val_loss: 0.8047 - val_accuracy: 0.8346\n",
      "Epoch 7/10\n",
      "1662/1662 [==============================] - 179s 107ms/step - loss: 0.6395 - accuracy: 0.7946 - val_loss: 0.3866 - val_accuracy: 0.9035\n",
      "Epoch 8/10\n",
      "1662/1662 [==============================] - 181s 109ms/step - loss: 0.6151 - accuracy: 0.8012 - val_loss: 0.3268 - val_accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "1662/1662 [==============================] - 175s 105ms/step - loss: 0.6017 - accuracy: 0.8051 - val_loss: 0.4685 - val_accuracy: 0.8985\n",
      "Epoch 10/10\n",
      "1662/1662 [==============================] - 175s 105ms/step - loss: 0.5707 - accuracy: 0.8164 - val_loss: 0.3637 - val_accuracy: 0.9174\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_images,\n",
    "    Y_train,\n",
    "    validation_data=(X_test_images, Y_test),\n",
    "    epochs=10,\n",
    "    batch_size=25,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11516ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a824655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420aa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf053fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = model.predict(np.array([X_train_images[0],]))[0]\n",
    "np.argmax(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62bf4b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3d35a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomCrop in module tensorflow.python.keras.layers.preprocessing.image_preprocessing:\n",
      "\n",
      "class RandomCrop(tensorflow.python.keras.engine.base_preprocessing_layer.PreprocessingLayer)\n",
      " |  RandomCrop(*args, **kwargs)\n",
      " |  \n",
      " |  Randomly crop the images to target height and width.\n",
      " |  \n",
      " |  This layer will crop all the images in the same batch to the same cropping\n",
      " |  location.\n",
      " |  By default, random cropping is only applied during training. At inference\n",
      " |  time, the images will be first rescaled to preserve the shorter side, and\n",
      " |  center cropped. If you need to apply random cropping at inference time,\n",
      " |  set `training` to True when calling the layer.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, height, width, channels)`, data_format='channels_last'.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, target_height, target_width, channels)`.\n",
      " |  \n",
      " |  Args:\n",
      " |    height: Integer, the height of the output shape.\n",
      " |    width: Integer, the width of the output shape.\n",
      " |    seed: Integer. Used to create a random seed.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomCrop\n",
      " |      tensorflow.python.keras.engine.base_preprocessing_layer.PreprocessingLayer\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, height, width, seed=None, **kwargs)\n",
      " |  \n",
      " |  call(self, inputs, training=True)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Note here that `call()` method in `tf.keras` is little bit different\n",
      " |      from `keras` API. In `keras` API, you can pass support masking for\n",
      " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
      " |      method to support masking.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          *args: Additional positional arguments. Currently unused.\n",
      " |          **kwargs: Additional keyword arguments. Currently unused.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_preprocessing_layer.PreprocessingLayer:\n",
      " |  \n",
      " |  adapt(self, data, batch_size=None, steps=None, reset_state=True)\n",
      " |      Fits the state of the preprocessing layer to the data being passed.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          data: The data to train on. It can be passed either as a tf.data\n",
      " |            Dataset, or as a numpy array.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per state update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps' is None, the epoch will run until\n",
      " |              the input dataset is exhausted. When passing an infinitely\n",
      " |              repeating dataset, you must specify the `steps` argument. This\n",
      " |              argument is not supported with array inputs.\n",
      " |          reset_state: Optional argument specifying whether to clear the state of\n",
      " |            the layer at the start of the call to `adapt`, or whether to start\n",
      " |            from the existing state. This argument may not be relevant to all\n",
      " |            preprocessing layers: a subclass of PreprocessingLayer may choose to\n",
      " |            throw if 'reset_state' is set to False.\n",
      " |  \n",
      " |  compile(self, run_eagerly=None, steps_per_execution=None)\n",
      " |      Configures the layer for `adapt`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s logic\n",
      " |          will not be wrapped in a `tf.function`. Recommended to leave this as\n",
      " |          `None` unless your `Model` cannot be run inside a `tf.function`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to run\n",
      " |            during each `tf.function` call. Running multiple batches inside a\n",
      " |            single `tf.function` call can greatly improve performance on TPUs or\n",
      " |            small models with a large Python overhead.\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalize the statistics for the preprocessing layer.\n",
      " |      \n",
      " |      This method is called at the end of `adapt`. This method\n",
      " |      handles any one-time operations that should occur after all\n",
      " |      data has been seen.\n",
      " |  \n",
      " |  make_adapt_function(self)\n",
      " |      Creates a function to execute one step of `adapt`.\n",
      " |      \n",
      " |      This method can be overridden to support custom adapt logic.\n",
      " |      This method is called by `PreprocessingLayer.adapt`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` settings,\n",
      " |      and delegates the actual state update logic to\n",
      " |      `PreprocessingLayer.update_state`.\n",
      " |      \n",
      " |      This function is cached the first time `PreprocessingLayer.adapt`\n",
      " |      is called. The cache is cleared whenever `PreprocessingLayer.compile`\n",
      " |      is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, retrieve a batch, and update the state of the\n",
      " |        layer.\n",
      " |  \n",
      " |  merge_state(self, layers)\n",
      " |      Merge the statistics of multiple preprocessing layers.\n",
      " |      \n",
      " |      This layer will contain the merged state.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        layers: Layers whose statistics should be merge with the statistics of\n",
      " |          this layer.\n",
      " |  \n",
      " |  reset_state(self)\n",
      " |      Resets the statistics of the preprocessing layer.\n",
      " |  \n",
      " |  update_state(self, data)\n",
      " |      Accumulates statistics for the preprocessing layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A mini-batch of inputs to the layer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.base_preprocessing_layer.PreprocessingLayer:\n",
      " |  \n",
      " |  is_adapted\n",
      " |      Whether the layer has been fit to data already.\n",
      " |  \n",
      " |  streaming\n",
      " |      Whether `adapt` can be called twice without resetting the state.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from abc.ABCMeta\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from abc.ABCMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523be509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
